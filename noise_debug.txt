Noise: 0.000
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:57  acc: 0.7656 (0.7656)  time: 8.4531  data: 1.5392  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7670)  time: 4.8106  data: 0.0049  max mem: 10374
test: Total time: 0:01:44 (4.9914 s / it)
how2qa
test acc:  76.36%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7656 (0.7656)  time: 7.2085  data: 1.4590  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7670)  time: 4.8321  data: 0.0049  max mem: 10374
test: Total time: 0:01:44 (4.9533 s / it)
how2qa
test acc:  76.36%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://| distributed init (rank 3): env://

| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:49  acc: 0.7656 (0.7656)  time: 8.0511  data: 1.4816  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7670)  time: 4.8268  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9888 s / it)
how2qa
test acc:  76.36%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:33  acc: 0.7656 (0.7656)  time: 10.1529  data: 1.5382  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7670)  time: 4.8295  data: 0.0045  max mem: 10374
test: Total time: 0:01:46 (5.0903 s / it)
how2qa
test acc:  76.36%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7656 (0.7656)  time: 7.2868  data: 1.6014  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7670)  time: 4.8307  data: 0.0038  max mem: 10374
test: Total time: 0:01:44 (4.9548 s / it)
how2qa
test acc:  76.36%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.005
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:30  acc: 0.7812 (0.7812)  time: 10.0074  data: 1.5296  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7674)  time: 4.8298  data: 0.0047  max mem: 10374
test: Total time: 0:01:46 (5.0838 s / it)
how2qa
test acc:  76.40%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7734 (0.7734)  time: 7.2712  data: 1.6139  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7678)  time: 4.8318  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9589 s / it)
how2qa
test acc:  76.43%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:37  acc: 0.7656 (0.7656)  time: 7.5227  data: 1.5593  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7656)  time: 4.8338  data: 0.0055  max mem: 10374
test: Total time: 0:01:44 (4.9706 s / it)
how2qa
test acc:  76.20%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7656 (0.7656)  time: 7.2756  data: 1.5733  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7667)  time: 4.8278  data: 0.0042  max mem: 10374
test: Total time: 0:01:43 (4.9514 s / it)
how2qa
test acc:  76.32%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:41  acc: 0.7812 (0.7812)  time: 7.6700  data: 1.6599  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7693)  time: 4.8272  data: 0.0040  max mem: 10374
test: Total time: 0:01:44 (4.9708 s / it)
how2qa
test acc:  76.59%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.010
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:34  acc: 0.7891 (0.7891)  time: 7.3664  data: 1.6527  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7708)  time: 4.8265  data: 0.0044  max mem: 10374
test: Total time: 0:01:44 (4.9550 s / it)
how2qa
test acc:  76.74%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:37  acc: 0.7812 (0.7812)  time: 7.5163  data: 1.5380  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7693)  time: 4.8284  data: 0.0048  max mem: 10374
test: Total time: 0:01:44 (4.9635 s / it)
how2qa
test acc:  76.59%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:30  acc: 0.7656 (0.7656)  time: 7.1559  data: 1.5829  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7664)  time: 4.8310  data: 0.0056  max mem: 10374
test: Total time: 0:01:43 (4.9520 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:53  acc: 0.7422 (0.7422)  time: 8.2817  data: 1.5081  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7702)  time: 4.8328  data: 0.0045  max mem: 10374
test: Total time: 0:01:45 (5.0047 s / it)
how2qa
test acc:  76.47%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:45  acc: 0.7656 (0.7656)  time: 7.8726  data: 1.6043  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7682)  time: 4.8300  data: 0.0046  max mem: 10374
test: Total time: 0:01:44 (4.9828 s / it)
how2qa
test acc:  76.47%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.015
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:53  acc: 0.7734 (0.7734)  time: 8.2657  data: 1.5290  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7663)  time: 4.8258  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9968 s / it)
how2qa
test acc:  76.28%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:34  acc: 0.7578 (0.7578)  time: 7.3720  data: 1.8071  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7663)  time: 4.8261  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9547 s / it)
how2qa
test acc:  76.28%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:51  acc: 0.7734 (0.7734)  time: 8.1770  data: 1.5845  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7618)  time: 4.8255  data: 0.0044  max mem: 10374
test: Total time: 0:01:44 (4.9921 s / it)
how2qa
test acc:  75.81%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:39  acc: 0.7734 (0.7734)  time: 7.5739  data: 1.5184  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7624)  time: 4.8303  data: 0.0046  max mem: 10374
test: Total time: 0:01:44 (4.9684 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:37  acc: 0.7500 (0.7500)  time: 10.3633  data: 1.5626  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7685)  time: 4.8306  data: 0.0051  max mem: 10374
test: Total time: 0:01:47 (5.1039 s / it)
how2qa
test acc:  76.51%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.020
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:29  acc: 0.7734 (0.7734)  time: 7.1160  data: 1.5158  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7656 (0.7704)  time: 4.8273  data: 0.0045  max mem: 10374
test: Total time: 0:01:43 (4.9434 s / it)
how2qa
test acc:  76.71%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:48  acc: 0.7734 (0.7734)  time: 8.0014  data: 1.5752  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7679)  time: 4.8282  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9876 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:21  acc: 0.7500 (0.7500)  time: 9.6003  data: 1.5621  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7682)  time: 4.8285  data: 0.0043  max mem: 10374
test: Total time: 0:01:46 (5.0634 s / it)
how2qa
test acc:  76.47%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:57  acc: 0.7578 (0.7578)  time: 8.4535  data: 1.4853  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7694)  time: 4.8270  data: 0.0043  max mem: 10374
test: Total time: 0:01:45 (5.0068 s / it)
how2qa
test acc:  76.40%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:43  acc: 0.7422 (0.7422)  time: 7.8069  data: 1.7293  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7644)  time: 4.8281  data: 0.0040  max mem: 10374
test: Total time: 0:01:44 (4.9796 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.025
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:54  acc: 0.7578 (0.7578)  time: 8.3025  data: 1.3686  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7659)  time: 4.8257  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9982 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:45  acc: 0.7578 (0.7578)  time: 7.8851  data: 1.4937  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7637)  time: 4.8285  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9813 s / it)
how2qa
test acc:  76.01%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7500 (0.7500)  time: 7.2229  data: 1.5682  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7705)  time: 4.8297  data: 0.0041  max mem: 10374
test: Total time: 0:01:43 (4.9513 s / it)
how2qa
test acc:  76.51%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:20  acc: 0.7656 (0.7656)  time: 9.5379  data: 1.4858  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7629)  time: 4.8257  data: 0.0046  max mem: 10374
test: Total time: 0:01:46 (5.0584 s / it)
how2qa
test acc:  75.93%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7500 (0.7500)  time: 7.2444  data: 1.5776  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7702)  time: 4.8278  data: 0.0043  max mem: 10374
test: Total time: 0:01:43 (4.9509 s / it)
how2qa
test acc:  76.47%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.030
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:14  acc: 0.7578 (0.7578)  time: 9.2792  data: 1.4145  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7696)  time: 4.8293  data: 0.0051  max mem: 10374
test: Total time: 0:01:46 (5.0488 s / it)
how2qa
test acc:  76.63%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:50  acc: 0.7656 (0.7656)  time: 8.1268  data: 1.5836  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7672)  time: 4.8289  data: 0.0040  max mem: 10374
test: Total time: 0:01:44 (4.9932 s / it)
how2qa
test acc:  76.16%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:01  acc: 0.7656 (0.7656)  time: 8.6342  data: 1.5442  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7694)  time: 4.8271  data: 0.0039  max mem: 10374
test: Total time: 0:01:45 (5.0154 s / it)
how2qa
test acc:  76.40%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:01  acc: 0.7578 (0.7578)  time: 8.6236  data: 1.4846  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7699)  time: 4.8287  data: 0.0045  max mem: 10374
test: Total time: 0:01:45 (5.0161 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:53  acc: 0.7656 (0.7656)  time: 8.2634  data: 1.5932  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7679)  time: 4.8280  data: 0.0044  max mem: 10374
test: Total time: 0:01:44 (4.9984 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.035
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:53  acc: 0.7812 (0.7812)  time: 8.2394  data: 1.4888  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7650)  time: 4.8304  data: 0.0047  max mem: 10374
test: Total time: 0:01:45 (5.0006 s / it)
how2qa
test acc:  75.93%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:10  acc: 0.7578 (0.7578)  time: 9.0712  data: 1.3678  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7656 (0.7654)  time: 4.8281  data: 0.0045  max mem: 10374
test: Total time: 0:01:45 (5.0372 s / it)
how2qa
test acc:  76.40%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:13  acc: 0.7578 (0.7578)  time: 9.1968  data: 1.5737  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7618)  time: 4.8263  data: 0.0043  max mem: 10374
test: Total time: 0:01:45 (5.0417 s / it)
how2qa
test acc:  75.81%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:29  acc: 0.7500 (0.7500)  time: 7.1316  data: 1.5230  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7704)  time: 4.8274  data: 0.0045  max mem: 10374
test: Total time: 0:01:43 (4.9440 s / it)
how2qa
test acc:  76.71%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:24  acc: 0.7500 (0.7500)  time: 9.7404  data: 1.5946  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7682)  time: 4.8285  data: 0.0045  max mem: 10374
test: Total time: 0:01:46 (5.0702 s / it)
how2qa
test acc:  76.47%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.040
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:05  acc: 0.7500 (0.7500)  time: 8.8385  data: 1.5543  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7700)  time: 4.8304  data: 0.0040  max mem: 10374
test: Total time: 0:01:45 (5.0287 s / it)
how2qa
test acc:  76.67%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:43  acc: 0.7344 (0.7344)  time: 7.7957  data: 1.5663  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7603)  time: 4.8302  data: 0.0044  max mem: 10374
test: Total time: 0:01:44 (4.9785 s / it)
how2qa
test acc:  75.66%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:35  acc: 0.7578 (0.7578)  time: 7.3825  data: 1.5402  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7683)  time: 4.8304  data: 0.0055  max mem: 10374
test: Total time: 0:01:44 (4.9613 s / it)
how2qa
test acc:  76.28%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7500 (0.7500)  time: 7.2034  data: 1.5964  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7663)  time: 4.8273  data: 0.0041  max mem: 10374
test: Total time: 0:01:43 (4.9473 s / it)
how2qa
test acc:  76.28%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:43  acc: 0.7656 (0.7656)  time: 7.7932  data: 1.5762  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7653)  time: 4.8282  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9766 s / it)
how2qa
test acc:  75.97%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.045
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:30  acc: 0.7578 (0.7578)  time: 7.1620  data: 1.4872  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7690)  time: 4.8316  data: 0.0049  max mem: 10374
test: Total time: 0:01:43 (4.9511 s / it)
how2qa
test acc:  76.36%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:18  acc: 0.7422 (0.7422)  time: 9.4482  data: 1.5377  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7656 (0.7683)  time: 4.8281  data: 0.0044  max mem: 10374
test: Total time: 0:01:46 (5.0548 s / it)
how2qa
test acc:  76.28%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7578 (0.7578)  time: 7.2844  data: 1.6295  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7699)  time: 4.8288  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9539 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:50  acc: 0.7344 (0.7344)  time: 8.1011  data: 1.5446  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7666)  time: 4.8289  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9931 s / it)
how2qa
test acc:  75.89%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:35  acc: 0.7734 (0.7734)  time: 7.3835  data: 1.7168  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7741)  time: 4.8269  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9562 s / it)
how2qa
test acc:  77.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.050
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:45  acc: 0.7188 (0.7188)  time: 7.8946  data: 1.6420  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7664)  time: 4.8267  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9793 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:58  acc: 0.7578 (0.7578)  time: 8.5099  data: 1.7199  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7657)  time: 4.8308  data: 0.0052  max mem: 10374
test: Total time: 0:01:45 (5.0148 s / it)
how2qa
test acc:  76.01%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:55  acc: 0.7266 (0.7266)  time: 8.3727  data: 1.6477  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7661)  time: 4.8296  data: 0.0048  max mem: 10374
test: Total time: 0:01:45 (5.0069 s / it)
how2qa
test acc:  76.05%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:42  acc: 0.7656 (0.7656)  time: 7.7547  data: 1.5612  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7659)  time: 4.8305  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9774 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7500 (0.7500)  time: 7.2894  data: 1.5568  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7694)  time: 4.8296  data: 0.0054  max mem: 10374
test: Total time: 0:01:44 (4.9563 s / it)
how2qa
test acc:  76.40%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.055
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:02  acc: 0.7500 (0.7500)  time: 8.6742  data: 1.5144  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7627)  time: 4.8313  data: 0.0044  max mem: 10374
test: Total time: 0:01:45 (5.0213 s / it)
how2qa
test acc:  75.70%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:45  acc: 0.7344 (0.7344)  time: 7.8891  data: 1.6909  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7668)  time: 4.8279  data: 0.0040  max mem: 10374
test: Total time: 0:01:44 (4.9821 s / it)
how2qa
test acc:  76.12%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:30  acc: 0.7188 (0.7188)  time: 10.0377  data: 1.4316  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7653)  time: 4.8283  data: 0.0046  max mem: 10374
test: Total time: 0:01:46 (5.0837 s / it)
how2qa
test acc:  75.97%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:35  acc: 0.7266 (0.7266)  time: 7.3945  data: 1.5772  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7667)  time: 4.8274  data: 0.0035  max mem: 10374
test: Total time: 0:01:44 (4.9586 s / it)
how2qa
test acc:  76.32%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:51  acc: 0.7344 (0.7344)  time: 8.1435  data: 1.5752  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7631)  time: 4.8305  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9959 s / it)
how2qa
test acc:  75.74%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.060
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:27  acc: 0.7500 (0.7500)  time: 9.8953  data: 1.4786  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7578 (0.7674)  time: 4.8297  data: 0.0045  max mem: 10374
test: Total time: 0:01:46 (5.0793 s / it)
how2qa
test acc:  76.40%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:36  acc: 0.7500 (0.7500)  time: 7.4641  data: 1.4995  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7601)  time: 4.8315  data: 0.0051  max mem: 10374
test: Total time: 0:01:44 (4.9645 s / it)
how2qa
test acc:  75.43%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:51  acc: 0.7344 (0.7344)  time: 8.1515  data: 1.5512  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7679)  time: 4.8282  data: 0.0049  max mem: 10374
test: Total time: 0:01:44 (4.9940 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:10  acc: 0.7422 (0.7422)  time: 9.0920  data: 1.4380  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7644)  time: 4.8282  data: 0.0048  max mem: 10374
test: Total time: 0:01:45 (5.0395 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:44  acc: 0.7422 (0.7422)  time: 7.8565  data: 1.3769  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7616)  time: 4.8266  data: 0.0048  max mem: 10374
test: Total time: 0:01:44 (4.9777 s / it)
how2qa
test acc:  75.58%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.065
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:48  acc: 0.7734 (0.7734)  time: 8.0058  data: 1.5990  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7659)  time: 4.8255  data: 0.0039  max mem: 10374
test: Total time: 0:01:44 (4.9845 s / it)
how2qa
test acc:  76.24%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:36  acc: 0.7266 (0.7266)  time: 7.4380  data: 1.7177  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7618)  time: 4.8278  data: 0.0057  max mem: 10374
test: Total time: 0:01:44 (4.9626 s / it)
how2qa
test acc:  75.81%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:34  acc: 0.7656 (0.7656)  time: 7.3390  data: 1.6309  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7664)  time: 4.8273  data: 0.0040  max mem: 10374
test: Total time: 0:01:44 (4.9547 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:33  acc: 0.7266 (0.7266)  time: 10.1831  data: 1.5497  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7648)  time: 4.8282  data: 0.0040  max mem: 10374
test: Total time: 0:01:46 (5.0916 s / it)
how2qa
test acc:  76.12%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7344 (0.7344)  time: 7.3277  data: 1.6564  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7646)  time: 4.8278  data: 0.0048  max mem: 10374
test: Total time: 0:01:44 (4.9547 s / it)
how2qa
test acc:  75.89%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.070
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:12  acc: 0.7500 (0.7500)  time: 9.1522  data: 1.6051  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7656 (0.7657)  time: 4.8304  data: 0.0040  max mem: 10374
test: Total time: 0:01:45 (5.0432 s / it)
how2qa
test acc:  76.01%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:57  acc: 0.7500 (0.7500)  time: 8.4728  data: 1.4989  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7266 (0.7707)  time: 4.8315  data: 0.0046  max mem: 10374
test: Total time: 0:01:45 (5.0134 s / it)
how2qa
test acc:  76.32%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:24  acc: 0.7578 (0.7578)  time: 9.7481  data: 1.5623  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7596)  time: 4.8269  data: 0.0041  max mem: 10374
test: Total time: 0:01:46 (5.0691 s / it)
how2qa
test acc:  75.58%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:04  acc: 0.7188 (0.7188)  time: 8.7731  data: 1.6042  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7662)  time: 4.8293  data: 0.0043  max mem: 10374
test: Total time: 0:01:45 (5.0244 s / it)
how2qa
test acc:  75.85%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7500 (0.7500)  time: 7.2169  data: 1.6138  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7266 (0.7626)  time: 4.8271  data: 0.0047  max mem: 10374
test: Total time: 0:01:43 (4.9489 s / it)
how2qa
test acc:  75.89%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.075
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7266 (0.7266)  time: 7.2257  data: 1.5116  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7609)  time: 4.8277  data: 0.0041  max mem: 10374
test: Total time: 0:01:43 (4.9488 s / it)
how2qa
test acc:  75.50%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:24  acc: 0.7578 (0.7578)  time: 9.7513  data: 1.5750  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7681)  time: 4.8277  data: 0.0044  max mem: 10374
test: Total time: 0:01:46 (5.0695 s / it)
how2qa
test acc:  76.05%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7578 (0.7578)  time: 7.3282  data: 1.5793  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7629)  time: 4.8273  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9568 s / it)
how2qa
test acc:  75.50%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:07  acc: 0.7500 (0.7500)  time: 8.9388  data: 1.5622  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7629)  time: 4.8326  data: 0.0045  max mem: 10374
test: Total time: 0:01:45 (5.0349 s / it)
how2qa
test acc:  75.93%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:17  acc: 0.7266 (0.7266)  time: 9.4264  data: 1.6344  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7641)  time: 4.8279  data: 0.0040  max mem: 10374
test: Total time: 0:01:46 (5.0557 s / it)
how2qa
test acc:  76.05%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.080
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:34  acc: 0.7344 (0.7344)  time: 7.3586  data: 1.6384  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7683)  time: 4.8269  data: 0.0044  max mem: 10374
test: Total time: 0:01:44 (4.9567 s / it)
how2qa
test acc:  76.28%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:36  acc: 0.7188 (0.7188)  time: 7.4639  data: 1.5555  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7188 (0.7572)  time: 4.8292  data: 0.0041  max mem: 10374
test: Total time: 0:01:44 (4.9619 s / it)
how2qa
test acc:  75.54%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:05  acc: 0.7422 (0.7422)  time: 8.8467  data: 1.5124  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7563)  time: 4.8267  data: 0.0046  max mem: 10374
test: Total time: 0:01:45 (5.0249 s / it)
how2qa
test acc:  75.23%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7344 (0.7344)  time: 7.3150  data: 1.6216  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7609)  time: 4.8273  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9556 s / it)
how2qa
test acc:  75.50%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:28  acc: 0.7500 (0.7500)  time: 7.0527  data: 1.4263  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7641)  time: 4.8311  data: 0.0062  max mem: 10374
test: Total time: 0:01:43 (4.9460 s / it)
how2qa
test acc:  76.05%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.085
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:34  acc: 0.7188 (0.7188)  time: 7.3806  data: 1.5290  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7661)  time: 4.8265  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9555 s / it)
how2qa
test acc:  76.05%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7266 (0.7266)  time: 7.3206  data: 1.5554  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7635)  time: 4.8271  data: 0.0046  max mem: 10374
test: Total time: 0:01:44 (4.9531 s / it)
how2qa
test acc:  75.78%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:30  acc: 0.7344 (0.7344)  time: 7.1698  data: 1.4658  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7422 (0.7618)  time: 4.8323  data: 0.0054  max mem: 10374
test: Total time: 0:01:44 (4.9530 s / it)
how2qa
test acc:  75.81%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:07  acc: 0.7500 (0.7500)  time: 8.9061  data: 1.5897  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7607)  time: 4.8293  data: 0.0048  max mem: 10374
test: Total time: 0:01:45 (5.0312 s / it)
how2qa
test acc:  75.70%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:21  acc: 0.7422 (0.7422)  time: 9.6021  data: 1.4211  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7266 (0.7585)  time: 4.8275  data: 0.0044  max mem: 10374
test: Total time: 0:01:46 (5.0629 s / it)
how2qa
test acc:  75.47%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.090
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:29  acc: 0.7734 (0.7734)  time: 7.1165  data: 1.4861  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7685)  time: 4.8305  data: 0.0050  max mem: 10374
test: Total time: 0:01:43 (4.9466 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:40  acc: 0.7578 (0.7578)  time: 7.6585  data: 1.6833  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7627)  time: 4.8300  data: 0.0058  max mem: 10374
test: Total time: 0:01:44 (4.9746 s / it)
how2qa
test acc:  75.70%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7109 (0.7109)  time: 7.3083  data: 1.5444  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7640)  time: 4.8304  data: 0.0042  max mem: 10374
test: Total time: 0:01:44 (4.9565 s / it)
how2qa
test acc:  75.62%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:50  acc: 0.7188 (0.7188)  time: 8.1062  data: 1.5290  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7266 (0.7580)  time: 4.8275  data: 0.0042  max mem: 10374
test: Total time: 0:01:44 (4.9911 s / it)
how2qa
test acc:  75.00%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:38  acc: 0.7656 (0.7656)  time: 7.5357  data: 1.4264  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7598)  time: 4.8278  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9636 s / it)
how2qa
test acc:  75.81%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.095
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7188 (0.7188)  time: 7.2679  data: 1.4222  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7589)  time: 4.8286  data: 0.0051  max mem: 10374
test: Total time: 0:01:44 (4.9534 s / it)
how2qa
test acc:  75.50%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:51  acc: 0.7578 (0.7578)  time: 8.1874  data: 1.6843  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7609)  time: 4.8292  data: 0.0052  max mem: 10374
test: Total time: 0:01:44 (4.9973 s / it)
how2qa
test acc:  75.50%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:37  acc: 0.7344 (0.7344)  time: 7.5174  data: 1.5277  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7656 (0.7656)  time: 4.8269  data: 0.0049  max mem: 10374
test: Total time: 0:01:44 (4.9620 s / it)
how2qa
test acc:  76.20%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:56  acc: 0.7500 (0.7500)  time: 8.4158  data: 1.4758  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7607)  time: 4.8256  data: 0.0047  max mem: 10374
test: Total time: 0:01:45 (5.0041 s / it)
how2qa
test acc:  75.70%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:52  acc: 0.7031 (0.7031)  time: 8.2211  data: 1.5171  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7603)  time: 4.8270  data: 0.0044  max mem: 10374
test: Total time: 0:01:44 (4.9961 s / it)
how2qa
test acc:  75.66%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.100
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:24  acc: 0.7266 (0.7266)  time: 9.7180  data: 1.5797  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7266 (0.7514)  time: 4.8292  data: 0.0049  max mem: 10374
test: Total time: 0:01:46 (5.0707 s / it)
how2qa
test acc:  74.73%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7188 (0.7188)  time: 7.3295  data: 1.6701  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7589)  time: 4.8261  data: 0.0045  max mem: 10374
test: Total time: 0:01:44 (4.9557 s / it)
how2qa
test acc:  75.50%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:58  acc: 0.6875 (0.6875)  time: 8.5213  data: 1.6684  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7544)  time: 4.8300  data: 0.0048  max mem: 10374
test: Total time: 0:01:45 (5.0129 s / it)
how2qa
test acc:  75.04%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:17  acc: 0.7344 (0.7344)  time: 9.3884  data: 1.5197  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7646)  time: 4.8296  data: 0.0041  max mem: 10374
test: Total time: 0:01:46 (5.0544 s / it)
how2qa
test acc:  75.89%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:32  acc: 0.7656 (0.7656)  time: 10.1224  data: 1.5118  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7668)  time: 4.8331  data: 0.0042  max mem: 10374
test: Total time: 0:01:46 (5.0923 s / it)
how2qa
test acc:  76.12%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.105
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:49  acc: 0.7344 (0.7344)  time: 8.0728  data: 1.7252  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7520)  time: 4.8282  data: 0.0058  max mem: 10374
test: Total time: 0:01:44 (4.9925 s / it)
how2qa
test acc:  75.00%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7266 (0.7266)  time: 7.2103  data: 1.4795  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7718)  time: 4.8301  data: 0.0056  max mem: 10374
test: Total time: 0:01:44 (4.9527 s / it)
how2qa
test acc:  76.43%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:38  acc: 0.7188 (0.7188)  time: 7.5486  data: 1.7376  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7620)  time: 4.8310  data: 0.0051  max mem: 10374
test: Total time: 0:01:44 (4.9707 s / it)
how2qa
test acc:  75.62%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:40  acc: 0.7344 (0.7344)  time: 7.6564  data: 1.5881  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7266 (0.7560)  time: 4.8274  data: 0.0039  max mem: 10374
test: Total time: 0:01:44 (4.9702 s / it)
how2qa
test acc:  75.00%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:36  acc: 0.7344 (0.7344)  time: 7.4641  data: 1.5582  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7646)  time: 4.8322  data: 0.0049  max mem: 10374
test: Total time: 0:01:44 (4.9663 s / it)
how2qa
test acc:  75.89%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.110
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:24  acc: 0.7266 (0.7266)  time: 9.7579  data: 1.5466  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7615)  time: 4.8282  data: 0.0044  max mem: 10374
test: Total time: 0:01:46 (5.0697 s / it)
how2qa
test acc:  75.78%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:19  acc: 0.7344 (0.7344)  time: 9.4942  data: 1.4857  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7566)  time: 4.8282  data: 0.0047  max mem: 10374
test: Total time: 0:01:46 (5.0576 s / it)
how2qa
test acc:  75.27%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:50  acc: 0.7500 (0.7500)  time: 8.1204  data: 1.5171  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7638)  time: 4.8261  data: 0.0048  max mem: 10374
test: Total time: 0:01:44 (4.9901 s / it)
how2qa
test acc:  75.81%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:42  acc: 0.7969 (0.7969)  time: 7.7157  data: 1.5551  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7188 (0.7555)  time: 4.8304  data: 0.0055  max mem: 10374
test: Total time: 0:01:44 (4.9774 s / it)
how2qa
test acc:  75.16%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:57  acc: 0.7422 (0.7422)  time: 8.4400  data: 1.5016  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7652)  time: 4.8288  data: 0.0042  max mem: 10374
test: Total time: 0:01:45 (5.0081 s / it)
how2qa
test acc:  76.16%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.115
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:27  acc: 0.7500 (0.7500)  time: 7.0317  data: 1.4576  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7594)  time: 4.8263  data: 0.0049  max mem: 10374
test: Total time: 0:01:43 (4.9398 s / it)
how2qa
test acc:  75.35%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:45  acc: 0.7500 (0.7500)  time: 7.8628  data: 1.6631  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7644)  time: 4.8275  data: 0.0049  max mem: 10374
test: Total time: 0:01:44 (4.9790 s / it)
how2qa
test acc:  76.09%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:31  acc: 0.7266 (0.7266)  time: 7.2106  data: 1.5173  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7596)  time: 4.8269  data: 0.0047  max mem: 10374
test: Total time: 0:01:43 (4.9485 s / it)
how2qa
test acc:  75.58%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:29  acc: 0.6953 (0.6953)  time: 7.1411  data: 1.4911  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7266 (0.7597)  time: 4.8311  data: 0.0056  max mem: 10374
test: Total time: 0:01:43 (4.9495 s / it)
how2qa
test acc:  75.39%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7188 (0.7188)  time: 7.3186  data: 1.6285  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7535)  time: 4.8298  data: 0.0038  max mem: 10374
test: Total time: 0:01:44 (4.9550 s / it)
how2qa
test acc:  75.16%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.120
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7578 (0.7578)  time: 7.2982  data: 1.5729  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7188 (0.7586)  time: 4.8273  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9537 s / it)
how2qa
test acc:  75.27%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:57  acc: 0.7188 (0.7188)  time: 8.4709  data: 1.5237  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7266 (0.7610)  time: 4.8301  data: 0.0052  max mem: 10374
test: Total time: 0:01:45 (5.0130 s / it)
how2qa
test acc:  75.31%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:46  acc: 0.7109 (0.7109)  time: 7.9251  data: 1.6946  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7477)  time: 4.8275  data: 0.0048  max mem: 10374
test: Total time: 0:01:44 (4.9826 s / it)
how2qa
test acc:  74.34%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:46  acc: 0.7188 (0.7188)  time: 7.9347  data: 1.6772  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7633)  time: 4.8271  data: 0.0048  max mem: 10374
test: Total time: 0:01:44 (4.9839 s / it)
how2qa
test acc:  75.97%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:50  acc: 0.7188 (0.7188)  time: 8.1385  data: 1.6278  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7266 (0.7557)  time: 4.8264  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9915 s / it)
how2qa
test acc:  74.96%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.125
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:36  acc: 0.7344 (0.7344)  time: 7.4518  data: 1.5124  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7555)  time: 4.8278  data: 0.0046  max mem: 10374
test: Total time: 0:01:44 (4.9595 s / it)
how2qa
test acc:  75.16%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7266 (0.7266)  time: 7.2511  data: 1.5300  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7560)  time: 4.8251  data: 0.0050  max mem: 10374
test: Total time: 0:01:43 (4.9499 s / it)
how2qa
test acc:  75.00%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:33  acc: 0.7031 (0.7031)  time: 7.3070  data: 1.5138  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7618)  time: 4.8259  data: 0.0041  max mem: 10374
test: Total time: 0:01:43 (4.9522 s / it)
how2qa
test acc:  75.39%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:53  acc: 0.7188 (0.7188)  time: 8.2724  data: 1.5410  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7626)  time: 4.8277  data: 0.0039  max mem: 10374
test: Total time: 0:01:44 (4.9991 s / it)
how2qa
test acc:  75.89%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:59  acc: 0.7188 (0.7188)  time: 11.3954  data: 1.5173  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7344 (0.7542)  time: 4.8293  data: 0.0044  max mem: 10374
test: Total time: 0:01:48 (5.1490 s / it)
how2qa
test acc:  75.23%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.130
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:32  acc: 0.7500 (0.7500)  time: 7.2807  data: 1.6024  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7500 (0.7596)  time: 4.8258  data: 0.0049  max mem: 10374
test: Total time: 0:01:43 (4.9511 s / it)
how2qa
test acc:  75.58%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:53  acc: 0.7188 (0.7188)  time: 8.2392  data: 1.5517  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7650)  time: 4.8261  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9959 s / it)
how2qa
test acc:  75.93%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:34  acc: 0.7344 (0.7344)  time: 7.3686  data: 1.6356  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7344 (0.7616)  time: 4.8256  data: 0.0047  max mem: 10374
test: Total time: 0:01:44 (4.9547 s / it)
how2qa
test acc:  75.58%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:10  acc: 0.7266 (0.7266)  time: 9.0869  data: 1.5768  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7422 (0.7574)  time: 4.8275  data: 0.0045  max mem: 10374
test: Total time: 0:01:45 (5.0379 s / it)
how2qa
test acc:  75.35%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:38  acc: 0.7109 (0.7109)  time: 7.5483  data: 1.5501  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7578 (0.7603)  time: 4.8244  data: 0.0043  max mem: 10374
test: Total time: 0:01:44 (4.9612 s / it)
how2qa
test acc:  75.66%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Noise: 0.135
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:36  acc: 0.7344 (0.7344)  time: 7.4709  data: 1.6844  max mem: 9979
test:  [20/21]  eta: 0:00:04  acc: 0.7656 (0.7534)  time: 4.8265  data: 0.0042  max mem: 10374
test: Total time: 0:01:44 (4.9606 s / it)
how2qa
test acc:  74.73%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:24  acc: 0.7266 (0.7266)  time: 9.7244  data: 1.5174  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7641)  time: 4.8303  data: 0.0043  max mem: 10374
test: Total time: 0:01:46 (5.0722 s / it)
how2qa
test acc:  76.05%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:03:31  acc: 0.7188 (0.7188)  time: 10.0673  data: 1.5577  max mem: 9979
test:  [20/21]  eta: 0:00:05  acc: 0.7500 (0.7570)  time: 4.8262  data: 0.0041  max mem: 10374
test: Total time: 0:01:46 (5.0831 s / it)
how2qa
test acc:  75.31%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
Namespace(activitynet_features_path='ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='ActivityNet-QA/test.csv', activitynet_train_csv_path='ActivityNet-QA/train.csv', activitynet_val_csv_path='ActivityNet-QA/val.csv', activitynet_vocab_path='ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/mnt/ssd2/dataset/how2qa/openai_clip-vit-large-patch14', how2qa_subtitles_path='/mnt/hdd2/how2qa/frozenbilm/subtitles.pkl', how2qa_train_csv_path='How2QA/train.csv', how2qa_val_csv_path='/mnt/hdd2/how2qa/frozenbilm/public_val_sanitized.csv', ivqa_features_path='iVQA/clipvitl14.pth', ivqa_subtitles_path='iVQA/subtitles.pkl', ivqa_test_csv_path='iVQA/test.csv', ivqa_train_csv_path='iVQA/train.csv', ivqa_val_csv_path='iVQA/val.csv', ivqa_vocab_path='iVQA/vocab.json', load='/workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='LSMDC/clipvitl14.pth', lsmdc_subtitles_path='LSMDC/subtitles.pkl', lsmdc_test_csv_path='LSMDC/test.csv', lsmdc_train_csv_path='LSMDC/training.csv', lsmdc_val_csv_path='LSMDC/val.csv', lsmdc_vocab_path='LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='microsoft/deberta-v2-xlarge', msrvtt_features_path='MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='MSRVTT-QA/test.csv', msrvtt_train_csv_path='MSRVTT-QA/train.csv', msrvtt_val_csv_path='MSRVTT-QA/val.csv', msrvtt_vocab_path='MSRVTT-QA/vocab.json', msvd_features_path='MSVD-QA/clipvitl14.pth', msvd_subtitles_path='MSVD-QA/subtitles.pkl', msvd_test_csv_path='MSVD-QA/test.csv', msvd_train_csv_path='MSVD-QA/train.csv', msvd_val_csv_path='MSVD-QA/val.csv', msvd_vocab_path='MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, save_dir='zsHow2QA', schedule='', scratch=False, seed=42, start_epoch=0, suffix='.', test=True, tgif_features_path='TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='TGIF-QA/train_frameqa.csv', tgif_vocab_path='TGIF-QA/vocab.json', tvqa_features_path='TVQA/clipvitl14.pth', tvqa_subtitles_path='TVQA/subtitles.pkl', tvqa_test_csv_path='TVQA/test_public.csv', tvqa_train_csv_path='TVQA/train.csv', tvqa_val_csv_path='TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='VQA/clipvitl14.pth', vqa_train_pkl_path='VQA/train_list.pkl', vqa_val_pkl_path='VQA/val_list.csv', vqa_vocab_path='VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='WebVid/train_captions.csv', webvid_val_csv_path='WebVid/val_captions.csv', weight_decay=0, world_size=4)
number of params: 29735424
loading from /workspace/data/frozenbilm/checkpoints/frozenbilm_how2qa.pth
test:  [ 0/21]  eta: 0:02:35  acc: 0.7188 (0.7188)  time: 7.4093  data: 1.5284  max mem: 9979
